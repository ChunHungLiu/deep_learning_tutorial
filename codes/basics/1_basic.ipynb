{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow config (optional)\n",
    "TensorFlow는 디폴트 설정에 의해 GPU 메모리를 모두 점유하기 때문에 다수가 접속하는 서버에서는 아래와 같은 설정을 통해 이를 방지하도록 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess_config = tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow 세션"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"ones:0\", shape=(2, 2), dtype=float32)\n",
      "[[ 1.  1.]\n",
      " [ 1.  1.]]\n",
      "[ 2.  2.]\n",
      "[[ 1.  1.  1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session(config=sess_config)\n",
    "\n",
    "a = tf.ones((2, 2))\n",
    "b = tf.reduce_sum(a, axis=1)\n",
    "c = tf.reshape(a, (1, 4))\n",
    "\n",
    "print(a)\n",
    "print(sess.run(a))\n",
    "print(sess.run(b))\n",
    "print(sess.run(c))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5 6]]\n",
      "[[5]\n",
      " [6]]\n",
      "[[25 30]\n",
      " [30 36]]\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([[5, 6]])\n",
    "b = tf.constant([[5], [6]])\n",
    "c = a*b\n",
    "\n",
    "with tf.Session(config=sess_config) as sess:\n",
    "    print(sess.run(a))\n",
    "    print(sess.run(b))\n",
    "    print(sess.run(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.08993217 -0.13364786]\n",
      " [ 0.15204987  0.08158098]\n",
      " [-0.00338036 -0.09407447]\n",
      " [-0.07901672  0.06409153]\n",
      " [-0.08955514 -0.00680354]]\n",
      "[[3 2 3]\n",
      " [1 2 3]]\n"
     ]
    }
   ],
   "source": [
    "w1 = tf.Variable(tf.random_normal([5, 2], stddev=0.1))\n",
    "w2 = tf.Variable([[3, 2, 3], [1, 2, 3]])\n",
    "\n",
    "with tf.Session(config=sess_config) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    w1_fetch, w2_fetch = sess.run([w1, w2])\n",
    "    print(w1_fetch)\n",
    "    print(w2_fetch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inital:  0\n",
      "update 0:  1\n",
      "update 1:  2\n",
      "update 2:  3\n"
     ]
    }
   ],
   "source": [
    "state = tf.Variable(0, name=\"counter\")\n",
    "new_value = tf.add(state, tf.constant(1))\n",
    "update = tf.assign(state, new_value)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(\"inital: \", sess.run(state))\n",
    "    for i in range(3):\n",
    "        sess.run(update)\n",
    "        print(\"update {}: \".format(i), sess.run(state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"a:0\", dtype=float32)\n",
      "Tensor(\"b:0\", dtype=float32)\n",
      "5.0\n",
      "20.0\n"
     ]
    }
   ],
   "source": [
    "a = tf.placeholder(tf.float32, name=\"a\")\n",
    "b = tf.placeholder(tf.float32, name=\"b\")\n",
    "\n",
    "print(a)\n",
    "print(b)\n",
    "\n",
    "add = a+b\n",
    "mul = a*b\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(add, feed_dict={a: 2, b: 3}))\n",
    "    print(sess.run(mul, feed_dict={a: 4, b: 5}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.  3.]\n",
      " [ 2.  2.]]\n",
      "[[ 2.  1.]\n",
      " [ 2.  1.]]\n",
      "[[ 12.   6.]\n",
      " [  8.   4.]]\n"
     ]
    }
   ],
   "source": [
    "matrix1 = tf.placeholder(tf.float32, [2, 2])\n",
    "matrix2 = tf.placeholder(tf.float32, [2, 2])\n",
    "product = tf.matmul(matrix1, matrix2)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    mv1 = np.array([[3., 3.], [2., 2.]])\n",
    "    mv2 = np.array([[2., 1.], [2., 1.]])\n",
    "    result = sess.run(product, feed_dict={matrix1: mv1, matrix2: mv2})\n",
    "    print(mv1)\n",
    "    print(mv2)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 퍼셉트론으로 AND, OR 문제 풀기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 100 loss: 0.360255 gt: [0 0 0 1] predict: [0 0 0 1]\n",
      "step 200 loss: 0.251539 gt: [0 0 0 1] predict: [0 0 0 1]\n",
      "step 300 loss: 0.197987 gt: [0 0 0 1] predict: [0 0 0 1]\n",
      "step 400 loss: 0.164111 gt: [0 0 0 1] predict: [0 0 0 1]\n",
      "step 500 loss: 0.140213 gt: [0 0 0 1] predict: [0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "and_x = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "and_y = np.array([0, 0, 0, 1])\n",
    "or_x  = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "or_y  = np.array([0, 1, 1, 1])\n",
    "\n",
    "learning_rate = 0.1\n",
    "\n",
    "inputs = tf.placeholder(tf.float32, [None, 2])\n",
    "label  = tf.placeholder(tf.int64, [None])\n",
    "weight = tf.Variable(tf.random_normal([2, 2]))\n",
    "bias   = tf.Variable(tf.zeros([2]))\n",
    "\n",
    "logit = tf.matmul(inputs, weight) + bias\n",
    "pred_op = tf.nn.softmax(logit)\n",
    "\n",
    "loss_op = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=label, logits=logit))\n",
    "opt = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss_op)\n",
    "\n",
    "with tf.Session(config=sess_config) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(500):\n",
    "        _, loss = sess.run([opt, loss_op], feed_dict={inputs:and_x, label:and_y})\n",
    "        if (step+1)%100 == 0:\n",
    "            pred = sess.run(pred_op, feed_dict={inputs:and_x, label:and_y})\n",
    "            print(\"step\", step+1, \"loss:\", loss, \"gt:\", and_y, \"predict:\", np.argmax(pred, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 퍼셉트론으로 XOR 문제 풀기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1000 loss: 0.693147 gt: [0 1 1 0] predict: [1 1 1 0]\n",
      "step 2000 loss: 0.693147 gt: [0 1 1 0] predict: [1 1 0 0]\n",
      "step 3000 loss: 0.693147 gt: [0 1 1 0] predict: [1 1 0 0]\n",
      "step 4000 loss: 0.693147 gt: [0 1 1 0] predict: [1 1 0 0]\n",
      "step 5000 loss: 0.693147 gt: [0 1 1 0] predict: [1 1 0 0]\n",
      "step 6000 loss: 0.693147 gt: [0 1 1 0] predict: [1 1 0 0]\n",
      "step 7000 loss: 0.693147 gt: [0 1 1 0] predict: [1 1 0 0]\n",
      "step 8000 loss: 0.693147 gt: [0 1 1 0] predict: [1 1 0 0]\n",
      "step 9000 loss: 0.693147 gt: [0 1 1 0] predict: [1 1 0 0]\n",
      "step 10000 loss: 0.693147 gt: [0 1 1 0] predict: [1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "xor_x = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "xor_y = np.array([0, 1, 1, 0])\n",
    "\n",
    "learning_rate = 0.1\n",
    "\n",
    "inputs = tf.placeholder(tf.float32, [None, 2])\n",
    "label  = tf.placeholder(tf.int64, [None])\n",
    "weight = tf.Variable(tf.random_normal([2, 2]))\n",
    "bias   = tf.Variable(tf.zeros([2]))\n",
    "\n",
    "logit = tf.matmul(inputs, weight) + bias\n",
    "pred_op = tf.nn.softmax(logit)\n",
    "\n",
    "loss_op = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=label, logits=logit))\n",
    "opt = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss_op)\n",
    "\n",
    "with tf.Session(config=sess_config) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(10000):\n",
    "        _, loss = sess.run([opt, loss_op], feed_dict={inputs:xor_x, label:xor_y})\n",
    "        if (step+1)%1000 == 0:\n",
    "            pred = sess.run(pred_op, feed_dict={inputs:xor_x, label:xor_y})\n",
    "            print(\"step\", step+1, \"loss:\", loss, \"gt:\", xor_y, \"predict:\", np.argmax(pred, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 멀티 레이어 퍼셉트론으로 XOR 문제 풀기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1000 loss: 0.688865 gt: [1 0 0 1] predict: [1 1 0 0]\n",
      "step 2000 loss: 0.57285 gt: [1 0 0 1] predict: [1 0 0 0]\n",
      "step 3000 loss: 0.246368 gt: [1 0 0 1] predict: [1 0 0 1]\n",
      "step 4000 loss: 0.0634705 gt: [1 0 0 1] predict: [1 0 0 1]\n",
      "step 5000 loss: 0.0314783 gt: [1 0 0 1] predict: [1 0 0 1]\n",
      "step 6000 loss: 0.0203247 gt: [1 0 0 1] predict: [1 0 0 1]\n",
      "step 7000 loss: 0.0148462 gt: [1 0 0 1] predict: [1 0 0 1]\n",
      "step 8000 loss: 0.0116326 gt: [1 0 0 1] predict: [1 0 0 1]\n",
      "step 9000 loss: 0.00953384 gt: [1 0 0 1] predict: [1 0 0 1]\n",
      "step 10000 loss: 0.00806128 gt: [1 0 0 1] predict: [1 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "xor_x = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "xor_y = np.array([1, 0, 0, 1])\n",
    "\n",
    "learning_rate = 0.1\n",
    "\n",
    "inputs = tf.placeholder(tf.float32, [None, 2])\n",
    "label  = tf.placeholder(tf.int64, [None])\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([2, 2]))\n",
    "b1 = tf.Variable(tf.zeros([2]))\n",
    "W2 = tf.Variable(tf.random_normal([2, 2]))\n",
    "b2 = tf.Variable(tf.zeros([2]))\n",
    "\n",
    "layer1 = tf.matmul(inputs, W1) + b1\n",
    "layer1 = tf.sigmoid(layer1)\n",
    "logit = tf.matmul(layer1, W2) + b2\n",
    "pred_op = tf.nn.softmax(logit)\n",
    "\n",
    "loss_op = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=label, logits=logit))\n",
    "opt = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss_op)\n",
    "\n",
    "with tf.Session(config=sess_config) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(10000):\n",
    "        _, loss = sess.run([opt, loss_op], feed_dict={inputs:xor_x, label:xor_y})\n",
    "        if (step+1)%1000 == 0:\n",
    "            pred = sess.run(pred_op, feed_dict={inputs:xor_x, label:xor_y})\n",
    "            print(\"step\", step+1, \"loss:\", loss, \"gt:\", xor_y, \"predict:\", np.argmax(pred, axis=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
